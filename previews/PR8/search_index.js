var documenterSearchIndex = {"docs":
[{"location":"#Documentation","page":"Documentation","title":"Documentation","text":"","category":"section"},{"location":"#Main-interface","page":"Documentation","title":"Main interface","text":"","category":"section"},{"location":"","page":"Documentation","title":"Documentation","text":"sdplr","category":"page"},{"location":"#SDPLRPlus.sdplr","page":"Documentation","title":"SDPLRPlus.sdplr","text":"sdplr(C, As, b, r)\nsdplr(C, As, b, r; kwargs...)\n\nThese functions tackle the following semidefinite program\n\nbeginaligned\n    textminimize_X succeq 0 quad    langle C  X rangle \n    textsubject toquad  langle A_i X rangle = b_i quad forall i in m\n                   X in mathbbR^n times n\nendaligned\n\nby factorizing the solution matrix X as YY^T and solve the following   nonlinear program instead.\n\nbeginaligned\n    textminimizequad    langle C  YY^T rangle \n    textsubject toquad  langle A_i YY^T rangle = b_i quad forall i in m\n                   Y in mathbbR^n times r\nendaligned\n\nArguments\n\nAs is a vector of m constraint matrices A_i of size n times n. There are four types of constraint matrices supported:  \nSparseMatrixCSC for sparse constraints with nnz Theta (n).\nSparseMatrixCOO for super sparse constraints with nnz o(n).\nSymLowRankMatrix for low-rank constraints with form BDB^T. \nDiagonal for diagonal constraints. Consider using SparseMatrixCOO instead if the diagonal matrix is super sparse.\nC is the cost matrix C of size n times n. Currently we support four types mentioned above.\nb is a vector of m right-hand side values b_i.\nr is the initial rank of the solution matrix Y.\n\nOptional arguments\n\nptol: Tolerance for relative primal infeasibility, i.e.\n\nmathcalA(YY^T) - b  (1 + b_2)\n\nThe default value is 10^-2. \n\nobjtol: Tolerance for relative suboptimality, i.e. \n\nlangle C YY^T rangle - langle C X^* rangle  (1 + langle C YY^T rangle)\n\nThe default value is 10^-2. \n\nnumberlbfgsvecs: Number of L-BFGS vectors. The default value is 4.\nfprec: Break one major iteration if the relative change of the    Lagrangian value is smaller than fprec * eps(). The default value    is 10^8, which is for moderate-accuracy solutions (ptol = objtol = 10^-2). \nprior_trace_bound: A trace bound priorly known or estimated.    For example, it is n for max cut. The default value is 10^18.\nσfac: Factor for increasing the smoothing factor sigma   in the augmented Lagrangian. The default value is 20.\nrankupd_tol: Rank update tolerance. After primal infeasibility    reaches ptol and objtol is not reached for rankupd_tol    major iterations, the rank of the solution matrix Y is doubled.   The default value is 4.\nmaxtime: Maximum time in seconds for the optimization. The default    value is 36000. There may be some postprocessing overhead so    the program will not stop exactly at maxtime. If you want to    achieve a hard time limit, use terminal tools.\nprintlevel: Print level. The default value is 1.\nprintfreq: How often to print in seconds. The default value is 600.\nmaxmajoriter: Maximum number of major iterations. The default value    is 10^5.\nmaxiter: Maximum number of total iterations. The default value is 10^7.\ndataset: Dataset name for better tracking progress,    especially when executed parallely. The default value is \"\".\neval_DIMACS_errs: Whether to evaluate DIMACS errors. The default value    is false.\n\n\n\n\n\n","category":"function"},{"location":"#Supported-constraint-types","page":"Documentation","title":"Supported constraint types","text":"","category":"section"},{"location":"","page":"Documentation","title":"Documentation","text":"SymLowRankMatrix\nSparseArrays.SparseMatrixCSC\nLinearAlgebra.Diagonal\nLuxurySparse.SparseMatrixCOO","category":"page"},{"location":"#SDPLRPlus.SymLowRankMatrix","page":"Documentation","title":"SDPLRPlus.SymLowRankMatrix","text":"SymLowRankMatrix{T} <: AbstractMatrix{T}\n\nSymmetric low-rank matrix of the form BDB^T with elements of type T. Besides the diagonal matrix D and the thin matrix B, we also store B^T as Bt. It's because usually B is really thin,  storing Bt doesn't cost too much more storage but will save allocation during computation.\n\n\n\n\n\n","category":"type"},{"location":"#SparseArrays.SparseMatrixCSC","page":"Documentation","title":"SparseArrays.SparseMatrixCSC","text":"SparseMatrixCSC{Tv,Ti<:Integer} <: AbstractSparseMatrixCSC{Tv,Ti}\n\nMatrix type for storing sparse matrices in the Compressed Sparse Column format. The standard way of constructing SparseMatrixCSC is through the sparse function. See also spzeros, spdiagm and sprand.\n\n\n\n\n\n","category":"type"},{"location":"#LinearAlgebra.Diagonal","page":"Documentation","title":"LinearAlgebra.Diagonal","text":"Diagonal(V::AbstractVector)\n\nConstruct a lazy matrix with V as its diagonal.\n\nSee also UniformScaling for the lazy identity matrix I, diagm to make a dense matrix, and diag to extract diagonal elements.\n\nExamples\n\njulia> d = Diagonal([1, 10, 100])\n3×3 Diagonal{Int64, Vector{Int64}}:\n 1   ⋅    ⋅\n ⋅  10    ⋅\n ⋅   ⋅  100\n\njulia> diagm([7, 13])\n2×2 Matrix{Int64}:\n 7   0\n 0  13\n\njulia> ans + I\n2×2 Matrix{Int64}:\n 8   0\n 0  14\n\njulia> I(2)\n2×2 Diagonal{Bool, Vector{Bool}}:\n 1  ⋅\n ⋅  1\n\nNote that a one-column matrix is not treated like a vector, but instead calls the method Diagonal(A::AbstractMatrix) which extracts 1-element diag(A):\n\njulia> A = transpose([7.0 13.0])\n2×1 transpose(::Matrix{Float64}) with eltype Float64:\n  7.0\n 13.0\n\njulia> Diagonal(A)\n1×1 Diagonal{Float64, Vector{Float64}}:\n 7.0\n\n\n\n\n\nDiagonal(A::AbstractMatrix)\n\nConstruct a matrix from the diagonal of A.\n\nExamples\n\njulia> A = permutedims(reshape(1:15, 5, 3))\n3×5 Matrix{Int64}:\n  1   2   3   4   5\n  6   7   8   9  10\n 11  12  13  14  15\n\njulia> Diagonal(A)\n3×3 Diagonal{Int64, Vector{Int64}}:\n 1  ⋅   ⋅\n ⋅  7   ⋅\n ⋅  ⋅  13\n\njulia> diag(A, 2)\n3-element Vector{Int64}:\n  3\n  9\n 15\n\n\n\n\n\nDiagonal{T}(undef, n)\n\nConstruct an uninitialized Diagonal{T} of length n. See undef.\n\n\n\n\n\n","category":"type"},{"location":"#LuxurySparse.SparseMatrixCOO","page":"Documentation","title":"LuxurySparse.SparseMatrixCOO","text":"SparseMatrixCOO(is::Vector, js::Vector, vs::Vector, m::Int, n::Int) -> SparseMatrixCOO\nSparseMatrixCOO{Tv, Ti}(is::Vector{Ti}, js::Vector{Ti}, vs::Vector{Tv}, m::Int, n::Int) -> SparseMatrixCOO\n\nA sparse matrix in COOrdinate format.\n\nValues vs are added to the matrix at rows is and columns js in a matrix with m rows and n columns.\n\nAlso known as the ‘ijv’ or ‘triplet’ format.\n\nNotes\n\nCOO matrices should not be used in arithmetic operations like addition, subtraction, multiplication, division, and matrix power.\n\nAdvantages of the COO format\n\nfacilitates fast conversion among sparse formats\npermits duplicate entries (see example)\nvery fast conversion to and from CSR/CSC formats (CSR is not implemented)\n\nDisadvantages of the COO format\n\ndoes not directly support:\n\narithmetic operations\nslicing\n\nIntended Usage\n\nCOO is a fast format for constructing sparse matrices\nOnce a matrix has been constructed, convert to CSR or CSC format for fast arithmetic and matrix vector operations\nBy default when converting to CSR or CSC format, duplicate (i,j) entries will be summed together. This facilitates efficient construction of finite element matrices and the like. (see example)\n\nExample\n\njulia> SparseMatrixCOO([4,3,1,2,2], [2,3,1,4,4], [1,2,3,4,5], 4,4) # duplicate entries at (2,4) summed together\n4×4 SparseMatrixCOO{Int64, Int64}:\n 3  0  0  0\n 0  0  0  9\n 0  0  2  0\n 0  1  0  0\n\n\n\n\n\n\n","category":"type"},{"location":"#Citing-SDPLRPlus","page":"Documentation","title":"Citing SDPLRPlus","text":"","category":"section"}]
}
